{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejercicio 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matpereira/Tp3-Grupo10/blob/main/Ejercicio_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fS9kfbfq1DT"
      },
      "source": [
        "# **Introduccion**\n",
        "\n",
        "Multiplica dos matrices cuadradas utilizando varios bloques y memoria compartida.\n",
        "A cada bloque de hilo se le asigna un \"mosaico\" de la matriz resultante y es responsable para generar los elementos en ese mosaico. Cada hilo de un bloque calcula un elemento del azulejo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9fXFh-JsewB"
      },
      "source": [
        "# **Armado del Ambiente**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnprtbhXjBlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e1fbb1-2127-4ebb-e2b8-30118ff4882e"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.7/dist-packages (2021.1)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.1.4)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.7/dist-packages (from pycuda) (2021.2.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePLQM89JZZu4"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import linalg as la\n",
        "from pycuda import driver, compiler, gpuarray, tools\n",
        "from datetime import datetime\n",
        "# -- initialize the device\n",
        "import pycuda.autoinit\n",
        "\n",
        "\n",
        "# define the (square) matrix size\n",
        "MATRIX_SIZE = 4000\n",
        "\n",
        "# define size of blocks and tiles sub-matrix\n",
        "# (we assume that the block size is same as tile size)\n",
        "TILE_SIZE = 20\n",
        "BLOCK_SIZE = TILE_SIZE\n",
        "\n",
        "# --------------------------------------------\n",
        "# Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "# --------------------------------------------\n",
        "\n",
        "a_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "b_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WKGrauWtY9p"
      },
      "source": [
        "# **Desarrollo CPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4H83MB8uEBP"
      },
      "source": [
        "tiempo_img = datetime.now()\n",
        "# compute reference on the CPU to verify GPU computation\n",
        "c_cpu = np.dot(a_cpu, b_cpu)\n",
        "tiempo_CPU = datetime.now() - tiempo_img"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEITiAb7te_I"
      },
      "source": [
        "# **Desarrollo GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM3LjfVXuuX9"
      },
      "source": [
        "tiempo_total_GPU = datetime.now()\n",
        "def matmul(a_gpu,b_gpu,MATRIX_SIZE=MATRIX_SIZE):\n",
        "    kernel_code_template = \"\"\"\n",
        "    __global__ void MatrixMulKernel(float *A, float *B, float *C)\n",
        "    {\n",
        "\n",
        "      const uint wA = %(MATRIX_SIZE)s;\n",
        "      const uint wB = %(MATRIX_SIZE)s;\n",
        "\n",
        "      // Block index\n",
        "      const uint bx = blockIdx.x;\n",
        "      const uint by = blockIdx.y;\n",
        "\n",
        "      // Thread index\n",
        "      const uint tx = threadIdx.x;\n",
        "      const uint ty = threadIdx.y;\n",
        "\n",
        "      // Index of the first sub-matrix of A processed by the block\n",
        "      const uint aBegin = wA * %(BLOCK_SIZE)s * by;\n",
        "      // Index of the last sub-matrix of A processed by the block\n",
        "      const uint aEnd = aBegin + wA - 1;\n",
        "      // Step size used to iterate through the sub-matrices of A\n",
        "      const uint aStep = %(BLOCK_SIZE)s;\n",
        "\n",
        "      // Index of the first sub-matrix of B processed by the block\n",
        "      const uint bBegin = %(BLOCK_SIZE)s * bx;\n",
        "      // Step size used to iterate through the sub-matrices of B\n",
        "      const uint bStep = %(BLOCK_SIZE)s * wB;\n",
        "\n",
        "      // The element of the block sub-matrix that is computed\n",
        "      // by the thread\n",
        "      float Csub = 0;\n",
        "      // Loop over all the sub-matrices of A and B required to\n",
        "      // compute the block sub-matrix\n",
        "      for (int a = aBegin, b = bBegin;\n",
        "           a <= aEnd;\n",
        "           a += aStep, b += bStep)\n",
        "        {\n",
        "          // Shared memory for the sub-matrix of A\n",
        "          __shared__ float As[%(BLOCK_SIZE)s][%(BLOCK_SIZE)s];\n",
        "          // Shared memory for the sub-matrix of B\n",
        "          __shared__ float Bs[%(BLOCK_SIZE)s][%(BLOCK_SIZE)s];\n",
        "\n",
        "          // Load the matrices from global memory to shared memory\n",
        "          // each thread loads one element of each matrix\n",
        "          As[ty][tx] = A[a + wA * ty + tx];\n",
        "          Bs[ty][tx] = B[b + wB * ty + tx];\n",
        "          // Synchronize to make sure the matrices are loaded\n",
        "          __syncthreads();\n",
        "\n",
        "          // Multiply the two matrices together;\n",
        "          // each thread computes one element\n",
        "          // of the block sub-matrix\n",
        "          for (int k = 0; k < %(BLOCK_SIZE)s; ++k)\n",
        "            Csub += As[ty][k] * Bs[k][tx];\n",
        "\n",
        "          // Synchronize to make sure that the preceding\n",
        "          // computation is done before loading two new\n",
        "          // sub-matrices of A and B in the next iteration\n",
        "          __syncthreads();\n",
        "        }\n",
        "\n",
        "      // Write the block sub-matrix to global memory;\n",
        "      // each thread writes one element\n",
        "      const uint c = wB * %(BLOCK_SIZE)s * by + %(BLOCK_SIZE)s * bx;\n",
        "      C[c + wB * ty + tx] = Csub;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    # get the kernel code from the template\n",
        "    # by specifying the constants MATRIX_SIZE and BLOCK_SIZE\n",
        "    kernel_code = kernel_code_template % {\n",
        "        'MATRIX_SIZE': MATRIX_SIZE,\n",
        "        'BLOCK_SIZE': BLOCK_SIZE,\n",
        "        }\n",
        "\n",
        "    # compile the kernel code\n",
        "    mod = compiler.SourceModule(kernel_code)\n",
        "    \n",
        "    # create empty gpu array for the result (C = A * B)\n",
        "    c_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "\n",
        "    # get the kernel function from the compiled module\n",
        "    matrixmul = mod.get_function(\"MatrixMulKernel\")\n",
        "\n",
        "    # call the kernel on the card\n",
        "\n",
        "    matrixmul(\n",
        "        # inputs\n",
        "        a_gpu, b_gpu,\n",
        "        # output\n",
        "        c_gpu,\n",
        "        # grid of multiple blocks\n",
        "        grid = (MATRIX_SIZE // TILE_SIZE, MATRIX_SIZE // TILE_SIZE),\n",
        "        # block of multiple threads\n",
        "        block = (TILE_SIZE, TILE_SIZE, 1),\n",
        "        )\n",
        "\n",
        "    return c_gpu\n",
        "\n",
        "\n",
        "\n",
        "# transfer host (CPU) memory to device (GPU) memory\n",
        "a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "tiempo_img2 = datetime.now()\n",
        "c_gpu = matmul(a_gpu,b_gpu)\n",
        "tiempo_GPU = datetime.now() - tiempo_img2\n",
        "\n",
        "tiempo_total_GPU = datetime.now() - tiempo_total_GPU"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXbJnyEhuNmn"
      },
      "source": [
        "# **Metricas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aeu_0RwSuLfI",
        "outputId": "cc844577-423e-47d9-f0a9-dde924142868"
      },
      "source": [
        "# print the results\n",
        "\n",
        "print(\"\\n\")\n",
        "print( \"Tiempo CPU:\", tiempo_en_ms( tiempo_CPU), \"[ms]\" )\n",
        "print(\"-\" * 8)\n",
        "print( \"Tiempo GPU:\", tiempo_en_ms(tiempo_GPU), \"[ms]\" )\n",
        "print(\"Tiempo TOTAL GPU: \", tiempo_en_ms( tiempo_total_GPU ), \"[ms]\" )\n",
        "print(\"\\n\")\n",
        "print(\"-\" * 80)\n",
        "print(\"Matriz C (CPU):\")\n",
        "print(c_cpu)\n",
        "\n",
        "print(\"-\" * 80)\n",
        "print(\"Matrix C (GPU):\")\n",
        "print(c_gpu.get())\n",
        "\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Tiempo CPU: 1096.717 [ms]\n",
            "--------\n",
            "Tiempo GPU: 270.895 [ms]\n",
            "Tiempo TOTAL GPU:  305.312 [ms]\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Matriz C (CPU):\n",
            "[[  63.54331    -29.097454   -10.1282425 ...   -8.06781    -40.361073\n",
            "     4.9087973]\n",
            " [ -48.93467    -56.057816  -134.8667    ...  -96.78839     25.50584\n",
            "  -108.41404  ]\n",
            " [ 103.30497    -11.911066    21.215227  ...   23.942415   -50.717957\n",
            "   -32.108284 ]\n",
            " ...\n",
            " [ -84.739075   -71.62523     -2.7986305 ...   19.566782    63.95124\n",
            "    11.666954 ]\n",
            " [  54.322556    53.524776    62.9317    ...  -50.570236    15.705193\n",
            "    82.816666 ]\n",
            " [ -75.878395   -57.258205   -63.2155    ...   -1.0665531   83.2072\n",
            "   -17.44794  ]]\n",
            "--------------------------------------------------------------------------------\n",
            "Matrix C (GPU):\n",
            "[[  63.543385   -29.097387   -10.128312  ...   -8.067886   -40.361214\n",
            "     4.908819 ]\n",
            " [ -48.934696   -56.057835  -134.8668    ...  -96.7883      25.505804\n",
            "  -108.414154 ]\n",
            " [ 103.30487    -11.911144    21.215265  ...   23.942408   -50.718006\n",
            "   -32.108276 ]\n",
            " ...\n",
            " [ -84.739105   -71.62528     -2.7986119 ...   19.566671    63.95113\n",
            "    11.6669855]\n",
            " [  54.32262     53.524815    62.931694  ...  -50.570183    15.70523\n",
            "    82.816734 ]\n",
            " [ -75.878456   -57.258232   -63.215446  ...   -1.0665772   83.207115\n",
            "   -17.447971 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MJ4xRMS8C-d"
      },
      "source": [
        "# **Conclusiones**\n",
        "\n",
        "Para resoluciones algebraicas es necesario que las dimensiones de las matrices sean muy grandes para que sea razonable utilizar una GPU para resolverlas, ya que si se trata de matrices con pequeñas dimensiones con solo utilizar el CPU se resuelve muchisimo mas rapido\n",
        "ya que: \n",
        "matriz 400*400  CPU > GPU\n",
        "matriz 4000*4000 GPU > CPU\n",
        "\n",
        "... que se yo algo asi (?  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k99v-uPM-SBu"
      },
      "source": [
        "# **Bibliografia**\n",
        "\n",
        "https://www.researchgate.net/publication/247933772_Multilevel_Optimization_of_Matrix_Multiplication_for_GPU-equipped_Systems\n",
        "https://colab.research.google.com/github/cbernet/maldives/blob/master/numba/numba_cuda_kernel.ipynb\n",
        "https://shephexd.github.io/development/2017/02/19/pycuda.html\n",
        "\n"
      ]
    }
  ]
}